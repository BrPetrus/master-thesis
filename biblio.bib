@article{Tran2024Programmed,
	author = {Tran, Ngan Vi and Montanari, Martti P and Gui, Jinghua and Lubenets, Dmitri and Fischbach, L{\' e}a Louise and Antson, Hanna and Huang, Yunxian and Brutus, Erich and Okada, Yasushi and Ishimoto, Yukitaka and T{\~ o}nissoo, Tambet and Shimmi, Osamu},
	journal = {The EMBO Journal},
	doi = {10.1038/s44318-023-00025-w},
	issn = {1460-2075},
	number = {4},
	year = {2024},
	month = {jan 23},
	pages = {568--594},
	publisher = {{Springer Science and Business Media LLC}},
	title = {Programmed disassembly of a microtubule-based membrane protrusion network coordinates 3D epithelial morphogenesis in {Drosophila}},
	url = {http://dx.doi.org/10.1038/s44318-023-00025-w},
	volume = {43},
}
@article{Ceran2022TNTdetect,
	author = {Ceran, Yasin and Erg{\" u}der, Hamza and Ladner, Katherine and Korenfeld, Sophie and Deniz, Karina and Padmanabhan, Sanyukta and Wong, Phillip and Baday, Murat and Pengo, Thomas and Lou, Emil and Patel, Chirag B.},
	journal = {Cancers},
	doi = {10.3390/cancers14194958},
	issn = {2072-6694},
	number = {19},
	year = {2022},
	month = {oct 10},
	pages = {4958},
	publisher = {MDPI AG},
	title = {TNTdetect.{AI}: A {Deep} {Learning} {Model} for {Automated} {Detection} and {Counting} of {Tunneling} {Nanotubes} in {Microscopy} {Images}},
	url = {http://dx.doi.org/10.3390/cancers14194958},
	volume = {14},
}
@article{Hodneland2006Automated,
	author = {Hodneland, Erlend and Lundervold, Arvid and Gurke, Steffen and Tai, XueCheng and Rustom, Amin and Gerdes, HansHermann},
	journal = {Cytometry Part A},
	doi = {10.1002/cyto.a.20302},
	issn = {1552-4922},
	number = {9},
	year = {2006},
	month = {9},
	pages = {961--972},
	publisher = {Wiley},
	title = {Automated detection of tunneling nanotubes in 3D images},
	url = {http://dx.doi.org/10.1002/cyto.a.20302},
	volume = {69A},
}
@misc{Ronneberger2015,
    title={U-Net: Convolutional Networks for Biomedical Image Segmentation},
    url={http://arxiv.org/abs/1505.04597},
    journal={arXiv.org},
    author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
    year={2015},
    month={May}
} 
@article{Mou2021,
    title = {CS2-Net: Deep learning segmentation of curvilinear structures in medical imaging},
    journal = {Medical Image Analysis},
    volume = {67},
    pages = {101874},
    year = {2021},
    issn = {1361-8415},
    doi = {https://doi.org/10.1016/j.media.2020.101874},
    url = {https://www.sciencedirect.com/science/article/pii/S1361841520302383},
    author = {Lei Mou and Yitian Zhao and Huazhu Fu and Yonghuai Liu and Jun Cheng and Yalin Zheng and Pan Su and Jianlong Yang and Li Chen and Alejandro F. Frangi and Masahiro Akiba and Jiang Liu},
    keywords = {Curvilinear structure, Blood vessel, Nerve fiber, Segmentation, Attention mechanism, Deep neural network},
    abstract = {Automated detection of curvilinear structures, e.g., blood
        vessels or nerve fibres, from medical and biomedical images is a crucial
            early step in automatic image interpretation associated to the
            management of many diseases. Precise measurement of the
            morphological changes of these curvilinear organ structures informs
            clinicians for understanding the mechanism, diagnosis, and treatment
            of e.g. cardiovascular, kidney, eye, lung, and neurological
            conditions. In this work, we propose a generic and unified
            convolution neural network for the segmentation of curvilinear
            structures and illustrate in several 2D/3D medical imaging
            modalities. We introduce a new curvilinear structure segmentation
            network (CS2-Net), which includes a self-attention mechanism in the
            encoder and decoder to learn rich hierarchical representations of
            curvilinear structures. Two types of attention modules - spatial
            attention and channel attention - are utilized to enhance the
            inter-class discrimination and intra-class responsiveness, to
            further integrate local features with their global dependencies and
            normalization, adaptively. Furthermore, to facilitate the
            segmentation of curvilinear structures in medical images, we employ
            a 1×3 and a 3×1 convolutional kernel to capture boundary features.
            Besides, we extend the 2D attention mechanism to 3D to enhance the
            network’s ability to aggregate depth information across different
            layers/slices. The proposed curvilinear structure segmentation
            network is thoroughly validated using both 2D and 3D images across
            six different imaging modalities. Experimental results across nine
            datasets show the proposed method generally outperforms other
            state-of-the-art algorithms in various metrics.}
}
@article{Rundo2019,
    title = {USE-Net: Incorporating Squeeze-and-Excitation blocks into U-Net for prostate zonal segmentation of multi-institutional MRI datasets},
    journal = {Neurocomputing},
    volume = {365},
    pages = {31-43},
    year = {2019},
    issn = {0925-2312},
    doi = {https://doi.org/10.1016/j.neucom.2019.07.006},
    url = {https://www.sciencedirect.com/science/article/pii/S0925231219309245},
    author = {Leonardo Rundo and Changhee Han and Yudai Nagano and Jin Zhang and Ryuichiro Hataya and Carmelo Militello and Andrea Tangherloni and Marco S. Nobile and Claudio Ferretti and Daniela Besozzi and Maria Carla Gilardi and Salvatore Vitabile and Giancarlo Mauri and Hideki Nakayama and Paolo Cazzaniga},
    keywords = {Prostate zonal segmentation, Prostate cancer, Anatomical MRI, Convolutional neural networks, USE-Net, Cross-dataset generalization},
}
@INPROCEEDINGS{Hu2018,
    author={Hu, Jie and Shen, Li and Sun, Gang},
    booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
    title={Squeeze-and-Excitation Networks}, 
    year={2018},
    volume={},
    number={},
    pages={7132-7141},
    keywords={Computer architecture;Computational modeling;Convolution;Task analysis;Convolutional codes;Adaptation models;Stacking},
    doi={10.1109/CVPR.2018.00745}
}
@online{uv2025,
    title={{uv}: An extremely fast Python package and project manager, written in Rust. },
    year=2025,
    url={https://docs.astral.sh/uv/},
    urldate={2025-10-29},
    author={Astral}
}
@misc{ma2020segmentationlossodyssey,
    title={Segmentation Loss Odyssey}, 
    author={Jun Ma},
    year={2020},
    eprint={2005.13449},
    archivePrefix={arXiv},
    primaryClass={eess.IV},
    url={https://arxiv.org/abs/2005.13449}, 
}
@misc{loshchilov2019,
    title={Decoupled Weight Decay Regularization}, 
    author={Ilya Loshchilov and Frank Hutter},
    year={2019},
    eprint={1711.05101},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1711.05101}, 
}
@misc{simonyan2015vgg,
    title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
    author={Karen Simonyan and Andrew Zisserman},
    year={2015},
    eprint={1409.1556},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/1409.1556}, 
}
@article{bibiloni2016curvilinear,
    title = {A survey on curvilinear object segmentation in multiple applications},
    journal = {Pattern Recognition},
    volume = {60},
    pages = {949-970},
    year = {2016},
    issn = {0031-3203},
    doi = {https://doi.org/10.1016/j.patcog.2016.07.023},
    url = {https://www.sciencedirect.com/science/article/pii/S0031320316301704},
    author = {P. Bibiloni and M. González-Hidalgo and S. Massanet},
    keywords = {Image processing, Pattern recognition, Curvilinear objects, Segmentation, Survey, Review},
    abstract = {Curvilinear object segmentation is a paramount step for many applications ranging from medical to aerial image processing. In particular, vessel segmentation in retinal images, detection of spiculated lesions in mammograms or extraction of airways in CT scans provide essential information to experts to evaluate, diagnose and propose a treatment. The significance of these applications has conducted important efforts to propose curvilinear object segmentation algorithms based on the most different techniques. The main objective of this review is to clearly present the similarities and differences between curvilinear structures in different applications and the different techniques used to segment them more effectively. To do so, we propose a general definition of curvilinear structures that encompasses the distinct models considered in the literature. In addition, we analyse and classify the mathematical techniques used to segment the curvilinear structures found across all considered applications, studying their strengths and weaknesses. In particular, we present the most relevant benchmarks related to curvilinear object segmentation as well as the best algorithms according to several performance measures. By doing so, it is acquired a wider point of view to extend the results from some fields to others, and to understand under which conditions some methodologies should be favoured over the rest of them.}
}
@article{kong2018roadsensing,
    title={Ridge–based curvilinear structure detection for identifying road in
        remote sensing image and backbone in neuron dendrite image},
    volume={77}, ISSN={1380-7501, 1573-7721}, DOI={10.1007/s11042-018-5976-7},
    abstractNote={The curvilinear structure detection is widely applied in many
        real tasks, such as the fiber classification, river finding, blood
            vessel detection, and so on. In this paper, we proposed to use the
            ridge-based curvilinear structure detection (RCSD) for the road
            extraction from the remote sensing images. First, we employed the
            morphology trivial opening operation to filter out almost all the
            small clusters of noise and the small paths. Then RCSD was used to
            find the road from the remote sensing images. The experiments showed
            that our proposed method is efficient and give better results than
            the current existing road-detection methods. Considering the similar
            structure between backbone in the neuron dendrite images and the
            road in remote sensing images, we extended the application of RCSD
            to the backbone detection in neuron dendrite images. The results on
            backbone detection also proved the efficiency of RCSD.},
    number={17},
    journal={Multimedia Tools and Applications},
    author={Kong, Fanqiang and Govindaraj, Vishnu Varthanan and Zhang, Yu-Dong},
    year={2018},
    month=sep, 
    pages={22857–22873}, 
    language={en}
}

@inproceedings{Vaswani2017attention,
    title={Attention is All you Need},
    volume={30},
    url={https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}, 
    booktitle={Advances in Neural Information Processing Systems},
    publisher={Curran Associates, Inc.},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Ł ukasz and Polosukhin, Illia},
    editor={Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
    year={2017}
}


@inproceedings{Jadon2020loss,
    address={Via del Mar, Chile},
    title={A survey of loss functions for semantic segmentation},
    rights={https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
    url={https://ieeexplore.ieee.org/document/9277638/},
    DOI={10.1109/cibcb48159.2020.9277638},
    abstractNote={Image Segmentation has been an active ﬁeld of research as it
        has a wide range of applications, ranging from automated disease
            detection to self driving cars. In the past ﬁve years, various
            papers came up with different objective loss functions used in
            different cases such as biased data, sparse segmentation, etc. In
            this paper, we have summarized some of the well-known loss functions
            widely used for Image Segmentation and listed out the cases where
            their usage can help in fast and better convergence of a model.
            Furthermore, we have also introduced a new log-cosh dice loss
            function and compared its performance on NBFS skull-segmentation
            open source data-set with widely used loss functions. We also
            showcased that certain loss functions perform well across all
            data-sets and can be taken as a good baseline choice in unknown data
            distribution scenarios.},
    booktitle={2020 IEEE Conference on Computational Intelligence in
        Bioinformatics and Computational Biology (CIBCB)},
    publisher={IEEE}, 
    author={Jadon, Shruti},
    year={2020}, 
    month=oct, 
    pages={1–7},
    language={en}
}


@misc{PyTorchBCE,
  author = {{\relax PyTorch Development Team}},
  title = {{torch.nn.BCEWithLogitsLoss} -- PyTorch Documentation},
  howpublished = {\url{https://docs.pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html}},
  note = {Version: stable. Accessed: November 28, 2025},
  year = {2025}
}

@book{Bishop2024DeepLearning,
    author = {Christopher M. Bishop and Hugh Bishop},
    title = {Deep Learning: Foundations and Concepts},
    year = {2024},
    publisher = {Springer}
}

@article{Zaharia2018MLflow,
    author = {Zaharia, Matei A. and Chen, Andrew and Davidson, Aaron and Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Murching, Siddharth and Nykodym, Tomas and Ogilvie, Paul and Parkhe, Mani and Xie, Fen and Zumar, Corey},
    journal = {IEEE Data Eng. Bull.},
    pages = {39--45},
    title = {{Accelerating the Machine Learning Lifecycle with MLflow}},
    url = {https://api.semanticscholar.org/CorpusID:83459546},
    volume = {41},
    year = {2018}
}

@misc{Ruff2025,
  author = {{Astral} and {Ruff contributors}},
  title = {{Ruff}: An extremely fast Python linter and code formatter, written in Rust},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/astral-sh/ruff},
}

@ARTICLE{Harris2020Numpy,
  author  = {Harris, Charles R. and Millman, K. Jarrod and
            van der Walt, Stéfan J and Gommers, Ralf and
            Virtanen, Pauli and Cournapeau, David and
            Wieser, Eric and Taylor, Julian and Berg, Sebastian and
            Smith, Nathaniel J. and Kern, Robert and Picus, Matti and
            Hoyer, Stephan and van Kerkwijk, Marten H. and
            Brett, Matthew and Haldane, Allan and
            Fernández del Río, Jaime and Wiebe, Mark and
            Peterson, Pearu and Gérard-Marchant, Pierre and
            Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and
            Abbasi, Hameer and Gohlke, Christoph and
            Oliphant, Travis E.},
  title   = {Array programming with {NumPy}},
  journal = {Nature},
  year    = {2020},
  volume  = {585},
  pages   = {357–362},
  doi     = {10.1038/s41586-020-2649-2}
}

@article{Pedregosa2011scikit,
    author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
    journal = {Journal of Machine Learning Research},
    pages = {2825--2830},
    title = {{Scikit-learn: Machine Learning in Python}},
    url = {https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html},
    volume = {12},
    year = {2011}
}

@article{vanderWalt2014skimage,
    author = {van der Walt, Stéfan J. and Schönberger, Johannes L. and Nunez-Iglesias, Juan and Boulogne, François and Warner, Joshua D. and Yager, Neil and Gouillart, Emmanuelle and Yu, Tony and the scikit-image contributors},
    doi = {10.7717/peerj.453},
    journal = {PeerJ},
    month = jun,
    pages = {e453},
    title = {{scikit-image: image processing in Python}},
    url = {https://doi.org/10.7717/peerj.453},
    volume = {2},
    year = {2014}
}

@inproceedings{Ansel2024PyTorch,
    author = {Ansel, Jason and Yang, Edward and He, Horace and Gimelshein, Natalia and Jain, Animesh and Voznesensky, Michael and Bao, Bin and Bell, Peter and Berard, David and Burovski, Evgeni and Chauhan, Geeta and Chourdia, Anjali and Constable, Will and Desmaison, Alban and DeVito, Zachary and Ellison, Elias and Feng, Will and Gong, Jiong and Gschwind, Michael and Hirsh, Brian and Huang, Sherlock and Kalambarkar, Kshiteej and Kirsch, Laurent and Lazos, Michael and Lezcano, Mario and Liang, Yanbo and Liang, Jason and Lu, Yinghai and Luk, CK and Maher, Bert and Pan, Yunjie and Puhrsch, Christian and Reso, Matthias and Saroufim, Mark and Siraichi, Marcos Yukio and Suk, Helen and Suo, Michael and Tillet, Phil and Wang, Eikan and Wang, Xiaodong and Wen, William and Zhang, Shunting and Zhao, Xu and Zhou, Keren and Zou, Richard and Mathews, Ajit and Chanan, Gregory and Wu, Peng and Chintala, Soumith},
    booktitle = {29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24)},
    doi = {10.1145/3620665.3640366},
    month = apr,
    publisher = {ACM},
    title = {{PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation}},
    url = {https://docs.pytorch.org/assets/pytorch2-2.pdf},
    year = {2024}
}

@article{Cardoso2022Monai,
    author = {Cardoso, M. Jorge and Li, Wenqi and Brown, Richard and Ma, Nic and Kerfoot, Eric and Wang, Yiheng and Murray, Benjamin and Myronenko, Andriy and Zhao, Can and Yang, Dong and Nath, Vishwesh and He, Yufan and Xu, Ziyue and Hatamizadeh, Ali and Zhu, Wentao and Liu, Yun and Zheng, Mingxin and Tang, Yucheng and Yang, Isaac and Zephyr, Michael and Hashemian, Behrooz and Alle, Sachidanand and Zalbagi Darestani, Mohammad and Budd, Charlie and Modat, Marc and Vercauteren, Tom and Wang, Guotai and Li, Yiwen and Hu, Yipeng and Fu, Yunguan and Gorman, Benjamin and Johnson, Hans and Genereaux, Brad and Erdal, Barbaros S. and Gupta, Vikash and Diaz-Pinto, Andres and Dourson, Andre and Maier-Hein, Lena and Jaeger, Paul F. and Baumgartner, Michael and Kalpathy-Cramer, Jayashree and Flores, Mona and Kirby, Justin and Cooper, Lee A.D. and Roth, Holger R. and Xu, Daguang and Bericat, David and Floca, Ralf and Zhou, S. Kevin and Shuaib, Haris and Farahani, Keyvan and Maier-Hein, Klaus H. and Aylward, Stephen and Dogra, Prerna and Ourselin, Sebastien and Feng, Andrew},
    doi = {https://doi.org/10.48550/arXiv.2211.02701},
    month = nov,
    title = {{MONAI: An open-source framework for deep learning in healthcare}},
    year = {2022}
}

@article{Hunter2007Matplotlib,
    author = {Hunter, John D.},
    doi = {10.1109/MCSE.2007.55},
    journal = {Computing in Science \& Engineering},
    number = {3},
    pages = {90--95},
    title = {{Matplotlib: A 2D graphics environment}},
    volume = {9},
    year = {2007}
}

@software{Python2025,
    author = {{Python Software Foundation}},
    title = {Python},
    version = {3.13},
    year = {2025},
    url = {https://docs.python.org/3.13/}
}

@software{Pandas,
    author = {{The pandas development team}},
    doi = {10.5281/zenodo.3509134},
    license = {BSD-3-Clause},
    title = {{pandas-dev/pandas: Pandas}},
    url = {https://github.com/pandas-dev/pandas}
    version = {2.3.3}
}
