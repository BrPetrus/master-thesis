@article{Tran2024Programmed,
	author = {Tran, Ngan Vi and Montanari, Martti P and Gui, Jinghua and Lubenets, Dmitri and Fischbach, L{\' e}a Louise and Antson, Hanna and Huang, Yunxian and Brutus, Erich and Okada, Yasushi and Ishimoto, Yukitaka and T{\~ o}nissoo, Tambet and Shimmi, Osamu},
	journal = {The EMBO Journal},
	doi = {10.1038/s44318-023-00025-w},
	issn = {1460-2075},
	number = {4},
	year = {2024},
	month = {jan 23},
	pages = {568--594},
	publisher = {{Springer Science and Business Media LLC}},
	title = {Programmed disassembly of a microtubule-based membrane protrusion network coordinates 3D epithelial morphogenesis in {Drosophila}},
	url = {http://dx.doi.org/10.1038/s44318-023-00025-w},
	volume = {43},
}
@article{Ceran2022TNTdetect,
	author = {Ceran, Yasin and Erg{\" u}der, Hamza and Ladner, Katherine and Korenfeld, Sophie and Deniz, Karina and Padmanabhan, Sanyukta and Wong, Phillip and Baday, Murat and Pengo, Thomas and Lou, Emil and Patel, Chirag B.},
	journal = {Cancers},
	doi = {10.3390/cancers14194958},
	issn = {2072-6694},
	number = {19},
	year = {2022},
	month = {oct 10},
	pages = {4958},
	publisher = {MDPI AG},
	title = {TNTdetect.{AI}: A {Deep} {Learning} {Model} for {Automated} {Detection} and {Counting} of {Tunneling} {Nanotubes} in {Microscopy} {Images}},
	url = {http://dx.doi.org/10.3390/cancers14194958},
	volume = {14},
}
@article{Hodneland2006Automated,
	author = {Hodneland, Erlend and Lundervold, Arvid and Gurke, Steffen and Tai, XueCheng and Rustom, Amin and Gerdes, HansHermann},
	journal = {Cytometry Part A},
	doi = {10.1002/cyto.a.20302},
	issn = {1552-4922},
	number = {9},
	year = {2006},
	month = {9},
	pages = {961--972},
	publisher = {Wiley},
	title = {Automated detection of tunneling nanotubes in 3D images},
	url = {http://dx.doi.org/10.1002/cyto.a.20302},
	volume = {69A},
}
@misc{Ronneberger2015,
    title={U-Net: Convolutional Networks for Biomedical Image Segmentation},
    url={http://arxiv.org/abs/1505.04597},
    journal={arXiv.org},
    author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
    year={2015},
    month={May}
} 
@article{Mou2021,
    title = {CS2-Net: Deep learning segmentation of curvilinear structures in medical imaging},
    journal = {Medical Image Analysis},
    volume = {67},
    pages = {101874},
    year = {2021},
    issn = {1361-8415},
    doi = {https://doi.org/10.1016/j.media.2020.101874},
    url = {https://www.sciencedirect.com/science/article/pii/S1361841520302383},
    author = {Lei Mou and Yitian Zhao and Huazhu Fu and Yonghuai Liu and Jun Cheng and Yalin Zheng and Pan Su and Jianlong Yang and Li Chen and Alejandro F. Frangi and Masahiro Akiba and Jiang Liu},
    keywords = {Curvilinear structure, Blood vessel, Nerve fiber, Segmentation, Attention mechanism, Deep neural network},
    abstract = {Automated detection of curvilinear structures, e.g., blood
        vessels or nerve fibres, from medical and biomedical images is a crucial
            early step in automatic image interpretation associated to the
            management of many diseases. Precise measurement of the
            morphological changes of these curvilinear organ structures informs
            clinicians for understanding the mechanism, diagnosis, and treatment
            of e.g. cardiovascular, kidney, eye, lung, and neurological
            conditions. In this work, we propose a generic and unified
            convolution neural network for the segmentation of curvilinear
            structures and illustrate in several 2D/3D medical imaging
            modalities. We introduce a new curvilinear structure segmentation
            network (CS2-Net), which includes a self-attention mechanism in the
            encoder and decoder to learn rich hierarchical representations of
            curvilinear structures. Two types of attention modules - spatial
            attention and channel attention - are utilized to enhance the
            inter-class discrimination and intra-class responsiveness, to
            further integrate local features with their global dependencies and
            normalization, adaptively. Furthermore, to facilitate the
            segmentation of curvilinear structures in medical images, we employ
            a 1×3 and a 3×1 convolutional kernel to capture boundary features.
            Besides, we extend the 2D attention mechanism to 3D to enhance the
            network’s ability to aggregate depth information across different
            layers/slices. The proposed curvilinear structure segmentation
            network is thoroughly validated using both 2D and 3D images across
            six different imaging modalities. Experimental results across nine
            datasets show the proposed method generally outperforms other
            state-of-the-art algorithms in various metrics.}
}
@article{Rundo2019,
title = {USE-Net: Incorporating Squeeze-and-Excitation blocks into U-Net for prostate zonal segmentation of multi-institutional MRI datasets},
journal = {Neurocomputing},
volume = {365},
pages = {31-43},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219309245},
author = {Leonardo Rundo and Changhee Han and Yudai Nagano and Jin Zhang and Ryuichiro Hataya and Carmelo Militello and Andrea Tangherloni and Marco S. Nobile and Claudio Ferretti and Daniela Besozzi and Maria Carla Gilardi and Salvatore Vitabile and Giancarlo Mauri and Hideki Nakayama and Paolo Cazzaniga},
keywords = {Prostate zonal segmentation, Prostate cancer, Anatomical MRI, Convolutional neural networks, USE-Net, Cross-dataset generalization},
abstract = {Prostate cancer is the most common malignant tumors in men but prostate Magnetic Resonance Imaging (MRI) analysis remains challenging. Besides whole prostate gland segmentation, the capability to differentiate between the blurry boundary of the Central Gland (CG) and Peripheral Zone (PZ) can lead to differential diagnosis, since the frequency and severity of tumors differ in these regions. To tackle the prostate zonal segmentation task, we propose a novel Convolutional Neural Network (CNN), called USE-Net, which incorporates Squeeze-and-Excitation (SE) blocks into U-Net, i.e., one of the most effective CNNs in biomedical image segmentation. Especially, the SE blocks are added after every Encoder (Enc USE-Net) or Encoder-Decoder block (Enc-Dec USE-Net). This study evaluates the generalization ability of CNN-based architectures on three T2-weighted MRI datasets, each one consisting of a different number of patients and heterogeneous image characteristics, collected by different institutions. The following mixed scheme is used for training/testing: (i) training on either each individual dataset or multiple prostate MRI datasets and (ii) testing on all three datasets with all possible training/testing combinations. USE-Net is compared against three state-of-the-art CNN-based architectures (i.e., U-Net, pix2pix, and Mixed-Scale Dense Network), along with a semi-automatic continuous max-flow model. The results show that training on the union of the datasets generally outperforms training on each dataset separately, allowing for both intra-/cross-dataset generalization. Enc USE-Net shows good overall generalization under any training condition, while Enc-Dec USE-Net remarkably outperforms the other methods when trained on all datasets. These findings reveal that the SE blocks’ adaptive feature recalibration provides excellent cross-dataset generalization when testing is performed on samples of the datasets used during training. Therefore, we should consider multi-dataset training and SE blocks together as mutually indispensable methods to draw out each other’s full potential. In conclusion, adaptive mechanisms (e.g., feature recalibration) may be a valuable solution in medical imaging applications involving multi-institutional settings.}
}
@INPROCEEDINGS{Hu2018,
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Squeeze-and-Excitation Networks}, 
  year={2018},
  volume={},
  number={},
  pages={7132-7141},
  keywords={Computer architecture;Computational modeling;Convolution;Task analysis;Convolutional codes;Adaptation models;Stacking},
  doi={10.1109/CVPR.2018.00745}
}
